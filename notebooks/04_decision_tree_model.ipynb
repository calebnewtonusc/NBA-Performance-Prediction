{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-title",
   "metadata": {},
   "source": [
    "# 04. Decision Tree Model\n",
    "\n",
    "This notebook implements a decision tree classifier for NBA game prediction.\n",
    "\n",
    "## Objectives\n",
    "- Build a decision tree classifier\n",
    "- Tune hyperparameters (depth, min_samples_split, etc.)\n",
    "- Visualize the decision tree\n",
    "- Compare performance to logistic regression baseline\n",
    "\n",
    "## Why Decision Trees?\n",
    "- Interpretable: Easy to understand decision rules\n",
    "- Non-linear: Can capture complex patterns\n",
    "- No feature scaling required\n",
    "- Handles interactions naturally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data_processing.cleaning import DataCleaner\n",
    "from src.data_processing.game_features import GameFeatureEngineer\n",
    "from src.data_processing.dataset_builder import DatasetBuilder\n",
    "from src.models.decision_tree_model import GameDecisionTree\n",
    "from src.models.logistic_regression_model import GameLogisticRegression\n",
    "from src.evaluation.model_comparison import ModelComparison\n",
    "from src.utils.data_loader import load_games_as_dataframe\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"âœ“ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare-data-header",
   "metadata": {},
   "source": [
    "## 1. Prepare Data (Same as Notebook 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "try:\n",
    "    games_df = load_games_as_dataframe(season=2023)\n",
    "except:\n",
    "    from scripts.generate_sample_data import generate_sample_games\n",
    "    games_df = pd.DataFrame(generate_sample_games(200))\n",
    "\n",
    "cleaner = DataCleaner()\n",
    "games_df = cleaner.clean_game_data(games_df)\n",
    "\n",
    "engineer = GameFeatureEngineer()\n",
    "features_df = engineer.create_game_features(games_df)\n",
    "\n",
    "builder = DatasetBuilder()\n",
    "dataset = builder.create_dataset(\n",
    "    df=features_df,\n",
    "    target_column='home_win',\n",
    "    date_column='date',\n",
    "    split_method='time',\n",
    "    scale_features=False,  # Decision trees don't need scaling!\n",
    "    exclude_columns=['game_id', 'home_team_id', 'away_team_id', 'home_score', 'away_score']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(dataset['X_train'])}\")\n",
    "print(f\"Features: {dataset['X_train'].shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 2. Train Decision Tree with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree\n",
    "dt_model = GameDecisionTree()\n",
    "\n",
    "print(\"Training Decision Tree with GridSearchCV...\")\n",
    "print(\"Testing combinations of: max_depth, min_samples_split, min_samples_leaf\")\n",
    "\n",
    "train_metrics = dt_model.train(\n",
    "    dataset['X_train'],\n",
    "    dataset['y_train'],\n",
    "    dataset['X_val'],\n",
    "    dataset['y_val'],\n",
    "    tune_hyperparameters=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST HYPERPARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Max Depth: {dt_model.model.max_depth}\")\n",
    "print(f\"Min Samples Split: {dt_model.model.min_samples_split}\")\n",
    "print(f\"Min Samples Leaf: {dt_model.model.min_samples_leaf}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in train_metrics.items():\n",
    "    print(f\"{metric:20s}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-header",
   "metadata": {},
   "source": [
    "## 3. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = dt_model.evaluate(dataset['X_test'], dataset['y_test'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST SET PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric:20s}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-tree-header",
   "metadata": {},
   "source": [
    "## 4. Visualize Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-tree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tree (top levels only)\n",
    "dt_model.visualize_tree(max_depth=3, figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tree-rules",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print decision rules\n",
    "print(\"Decision Rules (Top 5 levels):\")\n",
    "print(\"=\"*60)\n",
    "rules = dt_model.get_tree_rules(max_depth=5)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-importance-header",
   "metadata": {},
   "source": [
    "## 5. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = dt_model.get_feature_importance(dataset['feature_names'])\n",
    "\n",
    "# Plot\n",
    "top_features = importance_df.head(15)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance (Gini)')\n",
    "plt.title('Top 15 Features - Decision Tree')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Features:\")\n",
    "print(top_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## 6. Compare to Baseline (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline for comparison\n",
    "lr_model = GameLogisticRegression()\n",
    "lr_model.train(\n",
    "    dataset['X_train'],\n",
    "    dataset['y_train'],\n",
    "    dataset['X_val'],\n",
    "    dataset['y_val'],\n",
    "    tune_hyperparameters=False\n",
    ")\n",
    "\n",
    "# Compare\n",
    "comparison = ModelComparison(task_type='classification')\n",
    "comparison.add_model('Logistic Regression', lr_model, dataset['X_test'], dataset['y_test'])\n",
    "comparison.add_model('Decision Tree', dt_model, dataset['X_test'], dataset['y_test'])\n",
    "\n",
    "results = comparison.compare_all()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(results)\n",
    "\n",
    "best_model, _ = comparison.get_best_model()\n",
    "print(f\"\\nâœ“ Best Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-header",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "### Decision Tree Advantages\n",
    "- âœ“ Interpretable decision rules\n",
    "- âœ“ Captures non-linear patterns\n",
    "- âœ“ No feature scaling needed\n",
    "- âœ“ Shows which features drive decisions\n",
    "\n",
    "### Decision Tree Disadvantages\n",
    "- âœ— Can overfit on training data\n",
    "- âœ— Unstable (small data changes = different tree)\n",
    "- âœ— May not generalize as well\n",
    "\n",
    "### Performance vs Baseline\n",
    "Compare accuracy, precision, recall with logistic regression.\n",
    "\n",
    "### Next Steps\n",
    "â†’ Notebook 05: Try Random Forest (ensemble of decision trees) to reduce overfitting!\n",
    "\n",
    "ðŸŒ² Decision trees provide interpretable insights into game prediction!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
